{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEj_hpMcvU88",
        "outputId": "e49dc9be-83b9-4332-ec57-1d4fb450a128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "oUjogn_6wZf-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('/content/gdrive/MyDrive/archive/fuzzyc_means.csv')"
      ],
      "metadata": {
        "id": "E_RIYPYqwvp-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset.iloc[:, 0:9].values"
      ],
      "metadata": {
        "id": "NfAxTc9zw8P8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = dataset.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "gGbodPAkxHq8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQfYgD0PxN0t",
        "outputId": "441d5e7e-7907-4065-cfcc-a3cb1ababc0e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[8.98510e-02 8.38710e-01 3.69770e-01 ... 7.55560e-01 1.80000e-04\n",
            "  1.04200e-02]\n",
            " [6.63157e-01 8.81720e-01 3.02300e-02 ... 6.66670e-01 5.70000e-04\n",
            "  9.89580e-01]\n",
            " [1.80040e-02 9.78490e-01 2.76740e-01 ... 7.11110e-01 5.44000e-03\n",
            "  9.16670e-01]\n",
            " ...\n",
            " [1.14950e-02 7.84950e-01 4.65100e-02 ... 7.11110e-01 8.40000e-04\n",
            "  6.14580e-01]\n",
            " [1.40830e-02 8.49460e-01 2.79100e-02 ... 8.22220e-01 2.40000e-04\n",
            "  9.89580e-01]\n",
            " [5.64340e-02 6.98920e-01 3.67440e-01 ... 8.22220e-01 1.27000e-03\n",
            "  7.29200e-02]]\n",
            "[0 2 2 ... 2 2 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "3-e9OTonxOmE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "xg_bFp0cxPVM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "Ccviy6awxfWF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "BnOAXfrbxhbK"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "7xF__Jbyxjhj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = Sequential()"
      ],
      "metadata": {
        "id": "qGblhH5gxlWT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#classifier.add(Dense(units = 9,  activation = 'relu', input_dim = 9))"
      ],
      "metadata": {
        "id": "Snzj1wzxxm17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#classifier.add(Dense(units = 27, activation = 'relu'))"
      ],
      "metadata": {
        "id": "CQGNjbzhxpLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#classifier.add(Dense(units=1, activation = 'sigmoid'))"
      ],
      "metadata": {
        "id": "c5VqKx2gyBR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "gc7RrRLPyL-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# classifier.fit(X_train, y_train, batch_size = 9, nb_epoch = 100)"
      ],
      "metadata": {
        "id": "wXHCBAYdyaJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "classifier.add(Dense(9, kernel_initializer = 'uniform', activation = 'relu', input_dim = 9))\n",
        "classifier.add(Dense(36,kernel_initializer = 'uniform', activation = 'relu'))\n",
        "classifier.add(Dense(1, kernel_initializer = 'uniform', activation = 'sigmoid')) \n",
        "\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', \n",
        "                metrics = ['accuracy']) \n",
        "\n",
        "#classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)\n",
        "\n",
        "classifier.fit(X_train, y_train, batch_size = 9, epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBJqxJnkyce1",
        "outputId": "a98b63e3-6ff4-47a2-af00-fc64ad9899e6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "223/223 [==============================] - 1s 2ms/step - loss: -2.5975 - accuracy: 0.1936\n",
            "Epoch 2/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -66.6411 - accuracy: 0.2450\n",
            "Epoch 3/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -333.1426 - accuracy: 0.2690\n",
            "Epoch 4/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -926.6957 - accuracy: 0.2750\n",
            "Epoch 5/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -1933.1683 - accuracy: 0.2750\n",
            "Epoch 6/100\n",
            "223/223 [==============================] - 1s 3ms/step - loss: -3455.3721 - accuracy: 0.2725\n",
            "Epoch 7/100\n",
            "223/223 [==============================] - 1s 4ms/step - loss: -5525.9429 - accuracy: 0.2710\n",
            "Epoch 8/100\n",
            "223/223 [==============================] - 1s 4ms/step - loss: -8199.3320 - accuracy: 0.2725\n",
            "Epoch 9/100\n",
            "223/223 [==============================] - 1s 5ms/step - loss: -11546.5283 - accuracy: 0.2690\n",
            "Epoch 10/100\n",
            "223/223 [==============================] - 1s 5ms/step - loss: -15596.6543 - accuracy: 0.2695\n",
            "Epoch 11/100\n",
            "223/223 [==============================] - 1s 4ms/step - loss: -20355.8770 - accuracy: 0.2655\n",
            "Epoch 12/100\n",
            "223/223 [==============================] - 1s 5ms/step - loss: -25853.1543 - accuracy: 0.2625\n",
            "Epoch 13/100\n",
            "223/223 [==============================] - 1s 4ms/step - loss: -32070.7227 - accuracy: 0.2610\n",
            "Epoch 14/100\n",
            "223/223 [==============================] - 1s 4ms/step - loss: -39065.9062 - accuracy: 0.2595\n",
            "Epoch 15/100\n",
            "223/223 [==============================] - 1s 6ms/step - loss: -46895.2305 - accuracy: 0.2565\n",
            "Epoch 16/100\n",
            "223/223 [==============================] - 1s 6ms/step - loss: -55520.8477 - accuracy: 0.2585\n",
            "Epoch 17/100\n",
            "223/223 [==============================] - 1s 6ms/step - loss: -65019.4805 - accuracy: 0.2545\n",
            "Epoch 18/100\n",
            "223/223 [==============================] - 1s 3ms/step - loss: -75368.4844 - accuracy: 0.2540\n",
            "Epoch 19/100\n",
            "223/223 [==============================] - 1s 4ms/step - loss: -86530.1016 - accuracy: 0.2510\n",
            "Epoch 20/100\n",
            "223/223 [==============================] - 1s 4ms/step - loss: -98552.4141 - accuracy: 0.2500\n",
            "Epoch 21/100\n",
            "223/223 [==============================] - 1s 4ms/step - loss: -111456.3594 - accuracy: 0.2475\n",
            "Epoch 22/100\n",
            "223/223 [==============================] - 1s 6ms/step - loss: -125270.1484 - accuracy: 0.2480\n",
            "Epoch 23/100\n",
            "223/223 [==============================] - 2s 7ms/step - loss: -140019.9688 - accuracy: 0.2460\n",
            "Epoch 24/100\n",
            "223/223 [==============================] - 2s 8ms/step - loss: -155755.6094 - accuracy: 0.2465\n",
            "Epoch 25/100\n",
            "223/223 [==============================] - 2s 7ms/step - loss: -172489.1719 - accuracy: 0.2445\n",
            "Epoch 26/100\n",
            "223/223 [==============================] - 1s 5ms/step - loss: -190318.7500 - accuracy: 0.2445\n",
            "Epoch 27/100\n",
            "223/223 [==============================] - 1s 5ms/step - loss: -209182.9375 - accuracy: 0.2415\n",
            "Epoch 28/100\n",
            "223/223 [==============================] - 1s 5ms/step - loss: -229055.4688 - accuracy: 0.2430\n",
            "Epoch 29/100\n",
            "223/223 [==============================] - 1s 4ms/step - loss: -250009.8438 - accuracy: 0.2410\n",
            "Epoch 30/100\n",
            "223/223 [==============================] - 1s 4ms/step - loss: -272025.8125 - accuracy: 0.2400\n",
            "Epoch 31/100\n",
            "223/223 [==============================] - 1s 4ms/step - loss: -295232.5625 - accuracy: 0.2400\n",
            "Epoch 32/100\n",
            "223/223 [==============================] - 1s 3ms/step - loss: -319524.2500 - accuracy: 0.2385\n",
            "Epoch 33/100\n",
            "223/223 [==============================] - 1s 4ms/step - loss: -344913.6562 - accuracy: 0.2375\n",
            "Epoch 34/100\n",
            "223/223 [==============================] - 1s 3ms/step - loss: -371572.6562 - accuracy: 0.2375\n",
            "Epoch 35/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -399348.5938 - accuracy: 0.2370\n",
            "Epoch 36/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -428317.0938 - accuracy: 0.2355\n",
            "Epoch 37/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -458470.1562 - accuracy: 0.2360\n",
            "Epoch 38/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -489778.0625 - accuracy: 0.2350\n",
            "Epoch 39/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -522390.5000 - accuracy: 0.2345\n",
            "Epoch 40/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -556337.0625 - accuracy: 0.2350\n",
            "Epoch 41/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -591489.6250 - accuracy: 0.2335\n",
            "Epoch 42/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -627964.6250 - accuracy: 0.2330\n",
            "Epoch 43/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -665833.8750 - accuracy: 0.2335\n",
            "Epoch 44/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -705009.7500 - accuracy: 0.2335\n",
            "Epoch 45/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -745808.8750 - accuracy: 0.2335\n",
            "Epoch 46/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -787927.0625 - accuracy: 0.2335\n",
            "Epoch 47/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -831519.1875 - accuracy: 0.2335\n",
            "Epoch 48/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -876616.3125 - accuracy: 0.2325\n",
            "Epoch 49/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -923171.1875 - accuracy: 0.2330\n",
            "Epoch 50/100\n",
            "223/223 [==============================] - 1s 2ms/step - loss: -971207.0000 - accuracy: 0.2320\n",
            "Epoch 51/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -1020767.7500 - accuracy: 0.2320\n",
            "Epoch 52/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -1071961.6250 - accuracy: 0.2320\n",
            "Epoch 53/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -1124871.0000 - accuracy: 0.2320\n",
            "Epoch 54/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -1179291.8750 - accuracy: 0.2310\n",
            "Epoch 55/100\n",
            "223/223 [==============================] - 1s 2ms/step - loss: -1235177.1250 - accuracy: 0.2310\n",
            "Epoch 56/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -1292600.5000 - accuracy: 0.2310\n",
            "Epoch 57/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -1351751.1250 - accuracy: 0.2310\n",
            "Epoch 58/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -1412614.6250 - accuracy: 0.2310\n",
            "Epoch 59/100\n",
            "223/223 [==============================] - 1s 2ms/step - loss: -1474991.6250 - accuracy: 0.2305\n",
            "Epoch 60/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -1539126.0000 - accuracy: 0.2305\n",
            "Epoch 61/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -1604798.8750 - accuracy: 0.2305\n",
            "Epoch 62/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -1671953.8750 - accuracy: 0.2290\n",
            "Epoch 63/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -1740993.1250 - accuracy: 0.2295\n",
            "Epoch 64/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -1811492.3750 - accuracy: 0.2295\n",
            "Epoch 65/100\n",
            "223/223 [==============================] - 1s 2ms/step - loss: -1883450.5000 - accuracy: 0.2285\n",
            "Epoch 66/100\n",
            "223/223 [==============================] - 1s 2ms/step - loss: -1957242.8750 - accuracy: 0.2280\n",
            "Epoch 67/100\n",
            "223/223 [==============================] - 1s 2ms/step - loss: -2033289.0000 - accuracy: 0.2275\n",
            "Epoch 68/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -2111382.5000 - accuracy: 0.2275\n",
            "Epoch 69/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -2191306.2500 - accuracy: 0.2275\n",
            "Epoch 70/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -2273269.7500 - accuracy: 0.2270\n",
            "Epoch 71/100\n",
            "223/223 [==============================] - 1s 2ms/step - loss: -2357213.5000 - accuracy: 0.2260\n",
            "Epoch 72/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -2443103.0000 - accuracy: 0.2260\n",
            "Epoch 73/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -2530975.2500 - accuracy: 0.2255\n",
            "Epoch 74/100\n",
            "223/223 [==============================] - 1s 2ms/step - loss: -2620836.5000 - accuracy: 0.2255\n",
            "Epoch 75/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -2712592.0000 - accuracy: 0.2255\n",
            "Epoch 76/100\n",
            "223/223 [==============================] - 1s 2ms/step - loss: -2805817.5000 - accuracy: 0.2255\n",
            "Epoch 77/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -2901193.2500 - accuracy: 0.2255\n",
            "Epoch 78/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -2998607.2500 - accuracy: 0.2255\n",
            "Epoch 79/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -3097906.5000 - accuracy: 0.2255\n",
            "Epoch 80/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -3199209.7500 - accuracy: 0.2255\n",
            "Epoch 81/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -3302919.0000 - accuracy: 0.2255\n",
            "Epoch 82/100\n",
            "223/223 [==============================] - 1s 2ms/step - loss: -3408897.2500 - accuracy: 0.2250\n",
            "Epoch 83/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -3517186.2500 - accuracy: 0.2250\n",
            "Epoch 84/100\n",
            "223/223 [==============================] - 1s 2ms/step - loss: -3627987.2500 - accuracy: 0.2246\n",
            "Epoch 85/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -3741325.7500 - accuracy: 0.2246\n",
            "Epoch 86/100\n",
            "223/223 [==============================] - 1s 2ms/step - loss: -3856482.7500 - accuracy: 0.2246\n",
            "Epoch 87/100\n",
            "223/223 [==============================] - 1s 2ms/step - loss: -3973811.7500 - accuracy: 0.2246\n",
            "Epoch 88/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -4093350.2500 - accuracy: 0.2246\n",
            "Epoch 89/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -4215152.5000 - accuracy: 0.2246\n",
            "Epoch 90/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -4339267.5000 - accuracy: 0.2246\n",
            "Epoch 91/100\n",
            "223/223 [==============================] - 1s 2ms/step - loss: -4465997.0000 - accuracy: 0.2246\n",
            "Epoch 92/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -4594806.5000 - accuracy: 0.2246\n",
            "Epoch 93/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -4725932.0000 - accuracy: 0.2246\n",
            "Epoch 94/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -4859475.5000 - accuracy: 0.2246\n",
            "Epoch 95/100\n",
            "223/223 [==============================] - 1s 2ms/step - loss: -4995299.5000 - accuracy: 0.2246\n",
            "Epoch 96/100\n",
            "223/223 [==============================] - 1s 2ms/step - loss: -5133135.0000 - accuracy: 0.2246\n",
            "Epoch 97/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -5273562.0000 - accuracy: 0.2246\n",
            "Epoch 98/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -5416936.0000 - accuracy: 0.2250\n",
            "Epoch 99/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -5562294.0000 - accuracy: 0.2241\n",
            "Epoch 100/100\n",
            "223/223 [==============================] - 0s 2ms/step - loss: -5709829.0000 - accuracy: 0.2241\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efe8132f350>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "y_pred = (y_pred)"
      ],
      "metadata": {
        "id": "iiyARJQyysEc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnP0SvIBzzx0",
        "outputId": "dda0c343-96b9-460d-af60-2f76b0dc3c8e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsvUwVPfz2D8",
        "outputId": "1aa4030e-9c19-49a9-a39f-d3f03a265154"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 68  73   0   0]\n",
            " [ 58  43   0   0]\n",
            " [  7 107   0   0]\n",
            " [  0 146   0   0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Predicting result for Single Observation\n",
        "print(classifier.predict(([[5.3224,\t1.5469,\t8.2467,\t2.0020\t,2.9087\t,0.4234,\t4.4561,\t7.00544,\t3.1234\t]])) > 0.5)"
      ],
      "metadata": {
        "id": "bWqjy6Bk6faf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d978ae0-d63e-42f9-ff88-c3efd2eeff66"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[False]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#accuracy core on training data\n",
        "X_test_prediction = classifier.predict(X_test)\n",
        "test_data_accuracy = accuracy_score(y_test,X_test_prediction)"
      ],
      "metadata": {
        "id": "kcfOaReD0-yL"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy score of testing data : ', test_data_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWKUXYTm1EQs",
        "outputId": "d8ace8d5-bbfb-4778-8ebf-3f337d1129a1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score of testing data :  0.22111553784860558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YU_wCGjg1MAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Accuracy score of training data : ', training_data_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnQoV6040Pe9",
        "outputId": "e16dfef0-2f9c-45c5-dcba-a93fade15c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score of training data :  0.19211576846307385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "#accuracy core on training data\n",
        "X_train_prediction = classifier.predict(X_train)\n",
        "training_data_accuracy = accuracy_score(y_train,X_train_prediction)\n"
      ],
      "metadata": {
        "id": "apE7ryicz8BN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}